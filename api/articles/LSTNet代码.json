{"title":"LSTNet代码","uid":"21f0fb1c21f5c84a95aeb0eb674c5fc8","slug":"LSTNet代码","date":"2023-02-01T12:55:05.000Z","updated":"2023-02-01T13:30:18.256Z","comments":true,"path":"api/articles/LSTNet代码.json","keywords":null,"cover":null,"content":"<ul>\n<li>tensorflow</li>\n</ul>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">\n#######################################################################################################################\n#                                      End AR specific layers subsclass                                               #\n#######################################################################################################################\n\n#######################################################################################################################\n#                                                 Model Start                                                         #\n#                                                                                                                     #\n# The model, as per the paper has the following layers:                                                               #\n# - CNN                                                                                                               #\n# - GRU                                                                                                               #\n# - SkipGRU                                                                                                           #\n# - AR                                                                                                                #\n#######################################################################################################################\n\ndef LSTNetModel(init, input_shape):\n    \n    # m is the number of time-series\n    m &#x3D; input_shape[2]\n\n    # Get tensor shape except batchsize\n    tensor_shape &#x3D; input_shape[1:]\n    \n    if K.image_data_format() &#x3D;&#x3D; &#39;channels_last&#39;:\n        ch_axis &#x3D; 3\n    else:\n        ch_axis &#x3D; 1\n    \n    X &#x3D; Input(shape &#x3D; tensor_shape)\n\n    # CNN\n    if init.CNNFilters &gt; 0 and init.CNNKernel &gt; 0:\n        # Add an extra dimension of size 1 which is the channel dimension in Conv2D\n        C &#x3D; Reshape((input_shape[1], input_shape[2], 1))(X)\n\n\t# Apply a Conv2D that will transform it into data of dimensions (batchsize, time, 1, NumofFilters)\n        C &#x3D; Conv2D(filters&#x3D;init.CNNFilters, kernel_size&#x3D;(init.CNNKernel, m), kernel_initializer&#x3D;init.initialiser)(C)\n        C &#x3D; Dropout(init.dropout)(C)\n\n        # Adjust data dimensions by removing axis&#x3D;2 which is always equal to 1\n        c_shape &#x3D; K.int_shape(C)\n        C &#x3D; Reshape((c_shape[1], c_shape[3]))(C)\n    else:\n\t# If configured not to apply CNN, copy the input\n        C &#x3D; X\n    \n    # GRU\n    # Apply a GRU layer (with activation set to &#39;relu&#39; as per the paper) and take the returned states as result\n    _, R &#x3D; GRU(init.GRUUnits, activation&#x3D;&quot;relu&quot;, return_sequences &#x3D; False, return_state &#x3D; True)(C)\n    R    &#x3D; Dropout(init.dropout)(R)\n    \n    # SkipGRU\n    if init.skip &gt; 0:\n\t# Calculate the number of values to use which is equal to the window divided by how many time values to skip\n        pt   &#x3D; int(init.window &#x2F; init.skip)\n\n        S    &#x3D; PreSkipTrans(pt, int((init.window - init.CNNKernel + 1) &#x2F; pt))(C)\n        _, S &#x3D; GRU(init.SkipGRUUnits, activation&#x3D;&quot;relu&quot;, return_sequences &#x3D; False, return_state &#x3D; True)(S)\n        S    &#x3D; PostSkipTrans(int((init.window - init.CNNKernel + 1) &#x2F; pt))([S,X])\n\n\t# Concatenate the outputs of GRU and SkipGRU\n        R    &#x3D; Concatenate(axis&#x3D;1)([R,S])\n    \n    # Dense layer\n    Y &#x3D; Flatten()(R)\n    Y &#x3D; Dense(m)(Y)\n    \n    # AR\n    if init.highway &gt; 0:\n        Z &#x3D; PreARTrans(init.highway)(X)\n        Z &#x3D; Flatten()(Z)\n        Z &#x3D; Dense(1)(Z)\n        Z &#x3D; PostARTrans(m)([Z,X])\n\n\t# Generate output as the summation of the Dense layer output and the AR one\n        Y &#x3D; Add()([Y,Z])\n    \n    # Generate Model\n    model &#x3D; Model(inputs &#x3D; X, outputs &#x3D; Y)\n    \n    return model</code></pre>\n\n<ul>\n<li>pytorch</li>\n</ul>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, args, data):\n        super(Model, self).__init__()\n        self.use_cuda &#x3D; args.cuda\n        # 窗口大小\n        self.P &#x3D; args.window;\n        self.m &#x3D; data.m\n        self.hidR &#x3D; args.hidRNN;\n        self.hidC &#x3D; args.hidCNN;\n        self.hidS &#x3D; args.hidSkip;\n        # 卷积核\n        self.Ck &#x3D; args.CNN_kernel;\n        self.skip &#x3D; args.skip;\n        self.pt &#x3D; (self.P - self.Ck)&#x2F;self.skip\n        self.hw &#x3D; args.highway_window\n        #\n        self.conv1 &#x3D; nn.Conv2d(1, self.hidC, kernel_size &#x3D; (self.Ck, self.m));\n        self.GRU1 &#x3D; nn.GRU(self.hidC, self.hidR);\n        self.dropout &#x3D; nn.Dropout(p &#x3D; args.dropout);\n        if (self.skip &gt; 0):\n            self.GRUskip &#x3D; nn.GRU(self.hidC, self.hidS);\n            self.linear1 &#x3D; nn.Linear(self.hidR + self.skip * self.hidS, self.m);\n        else:\n            self.linear1 &#x3D; nn.Linear(self.hidR, self.m);\n        if (self.hw &gt; 0):\n            self.highway &#x3D; nn.Linear(self.hw, 1);\n        self.output &#x3D; None;\n        if (args.output_fun &#x3D;&#x3D; &#39;sigmoid&#39;):\n            self.output &#x3D; F.sigmoid;\n        if (args.output_fun &#x3D;&#x3D; &#39;tanh&#39;):\n            self.output &#x3D; F.tanh;\n \n    def forward(self, x):\n        batch_size &#x3D; x.size(0);\n        \n        #CNN：卷积神经网络\n        c &#x3D; x.view(-1, 1, self.P, self.m);\n        c &#x3D; F.relu(self.conv1(c));\n        c &#x3D; self.dropout(c);\n        c &#x3D; torch.squeeze(c, 3);\n        \n        # RNN：循环神经网络\n        r &#x3D; c.permute(2, 0, 1).contiguous();\n        _, r &#x3D; self.GRU1(r);\n        r &#x3D; self.dropout(torch.squeeze(r,0));\n\n        \n        #skip-rnn\n        \n        if (self.skip &gt; 0):\n            s &#x3D; c[:,:, int(-self.pt * self.skip):].contiguous();\n            s &#x3D; s.view(batch_size, self.hidC, self.pt, self.skip);\n            s &#x3D; s.permute(2,0,3,1).contiguous();\n            s &#x3D; s.view(self.pt, batch_size * self.skip, self.hidC);\n            _, s &#x3D; self.GRUskip(s);\n            s &#x3D; s.view(batch_size, self.skip * self.hidS);\n            s &#x3D; self.dropout(s);\n            r &#x3D; torch.cat((r,s),1);\n        \n        res &#x3D; self.linear1(r);\n        \n        #highway\n        if (self.hw &gt; 0):\n            z &#x3D; x[:, -self.hw:, :];\n            z &#x3D; z.permute(0,2,1).contiguous().view(-1, self.hw);\n            z &#x3D; self.highway(z);\n            z &#x3D; z.view(-1,self.m);\n            res &#x3D; res + z;\n            \n        if (self.output):\n            res &#x3D; self.output(res);\n        return res;\n    \n        \n        \n        \n</code></pre>\n\n","feature":true,"text":" tensorflow ####################################################################################################################### # End AR...","link":"","photos":[],"count_time":{"symbolsCount":"6.8k","symbolsTime":"6 mins."},"categories":[],"tags":[],"toc":"","author":{"name":"LiuQuanZe","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"a good guy!","socials":{"github":"https://github.com/liuquanze","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/weixin_45895853","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"comeback","uid":"cd0117f6419930cc841d1b89ddc82953","slug":"comeback","date":"2023-12-14T13:08:22.000Z","updated":"2023-12-14T13:10:25.425Z","comments":true,"path":"api/articles/comeback.json","keywords":null,"cover":null,"text":"我又回来了长时间没有写的，都快忘记怎么用了。 ","link":"","photos":[],"count_time":{"symbolsCount":23,"symbolsTime":"1 mins."},"categories":[{"name":"个人日志","slug":"个人日志","count":1,"path":"api/categories/个人日志.json"}],"tags":[{"name":"日常","slug":"日常","count":2,"path":"api/tags/日常.json"}],"author":{"name":"LiuQuanZe","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"a good guy!","socials":{"github":"https://github.com/liuquanze","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/weixin_45895853","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"01背包理论基础02","uid":"a684fe7136f12073d2c44da23dc49f83","slug":"01背包理论基础02","date":"2023-01-31T06:31:17.000Z","updated":"2023-01-31T06:42:27.179Z","comments":true,"path":"api/articles/01背包理论基础02.json","keywords":null,"cover":null,"text":"01背包理论基础02题目描述：有n件物品和一个最多能背重量为w 的背包。第i件物品的重量是weight[i]，得到的价值是value[i] 。每件物品只能用一次，求解将哪些物品装入背包里物品价值总和最大。 背包问题（一维数组d实现，滚动数组）对于背包问题其实状态都是可以压缩的。 ...","link":"","photos":[],"count_time":{"symbolsCount":"2k","symbolsTime":"2 mins."},"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","count":114,"path":"api/categories/数据结构与算法.json"}],"tags":[{"name":"Java","slug":"Java","count":123,"path":"api/tags/Java.json"},{"name":"动态规划","slug":"动态规划","count":14,"path":"api/tags/动态规划.json"}],"author":{"name":"LiuQuanZe","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"a good guy!","socials":{"github":"https://github.com/liuquanze","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/weixin_45895853","juejin":"","customs":{}}},"feature":true}}