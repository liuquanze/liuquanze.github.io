{"title":"LSTNet代码","uid":"21f0fb1c21f5c84a95aeb0eb674c5fc8","slug":"LSTNet代码","date":"2023-02-01T12:55:05.000Z","updated":"2023-02-01T12:59:16.178Z","comments":true,"path":"api/articles/LSTNet代码.json","keywords":null,"cover":null,"content":"<ul>\n<li>tensorflow</li>\n</ul>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">\n#######################################################################################################################\n#                                      End AR specific layers subsclass                                               #\n#######################################################################################################################\n\n#######################################################################################################################\n#                                                 Model Start                                                         #\n#                                                                                                                     #\n# The model, as per the paper has the following layers:                                                               #\n# - CNN                                                                                                               #\n# - GRU                                                                                                               #\n# - SkipGRU                                                                                                           #\n# - AR                                                                                                                #\n#######################################################################################################################\n\ndef LSTNetModel(init, input_shape):\n    \n    # m is the number of time-series\n    m &#x3D; input_shape[2]\n\n    # Get tensor shape except batchsize\n    tensor_shape &#x3D; input_shape[1:]\n    \n    if K.image_data_format() &#x3D;&#x3D; &#39;channels_last&#39;:\n        ch_axis &#x3D; 3\n    else:\n        ch_axis &#x3D; 1\n    \n    X &#x3D; Input(shape &#x3D; tensor_shape)\n\n    # CNN\n    if init.CNNFilters &gt; 0 and init.CNNKernel &gt; 0:\n        # Add an extra dimension of size 1 which is the channel dimension in Conv2D\n        C &#x3D; Reshape((input_shape[1], input_shape[2], 1))(X)\n\n\t# Apply a Conv2D that will transform it into data of dimensions (batchsize, time, 1, NumofFilters)\n        C &#x3D; Conv2D(filters&#x3D;init.CNNFilters, kernel_size&#x3D;(init.CNNKernel, m), kernel_initializer&#x3D;init.initialiser)(C)\n        C &#x3D; Dropout(init.dropout)(C)\n\n        # Adjust data dimensions by removing axis&#x3D;2 which is always equal to 1\n        c_shape &#x3D; K.int_shape(C)\n        C &#x3D; Reshape((c_shape[1], c_shape[3]))(C)\n    else:\n\t# If configured not to apply CNN, copy the input\n        C &#x3D; X\n    \n    # GRU\n    # Apply a GRU layer (with activation set to &#39;relu&#39; as per the paper) and take the returned states as result\n    _, R &#x3D; GRU(init.GRUUnits, activation&#x3D;&quot;relu&quot;, return_sequences &#x3D; False, return_state &#x3D; True)(C)\n    R    &#x3D; Dropout(init.dropout)(R)\n    \n    # SkipGRU\n    if init.skip &gt; 0:\n\t# Calculate the number of values to use which is equal to the window divided by how many time values to skip\n        pt   &#x3D; int(init.window &#x2F; init.skip)\n\n        S    &#x3D; PreSkipTrans(pt, int((init.window - init.CNNKernel + 1) &#x2F; pt))(C)\n        _, S &#x3D; GRU(init.SkipGRUUnits, activation&#x3D;&quot;relu&quot;, return_sequences &#x3D; False, return_state &#x3D; True)(S)\n        S    &#x3D; PostSkipTrans(int((init.window - init.CNNKernel + 1) &#x2F; pt))([S,X])\n\n\t# Concatenate the outputs of GRU and SkipGRU\n        R    &#x3D; Concatenate(axis&#x3D;1)([R,S])\n    \n    # Dense layer\n    Y &#x3D; Flatten()(R)\n    Y &#x3D; Dense(m)(Y)\n    \n    # AR\n    if init.highway &gt; 0:\n        Z &#x3D; PreARTrans(init.highway)(X)\n        Z &#x3D; Flatten()(Z)\n        Z &#x3D; Dense(1)(Z)\n        Z &#x3D; PostARTrans(m)([Z,X])\n\n\t# Generate output as the summation of the Dense layer output and the AR one\n        Y &#x3D; Add()([Y,Z])\n    \n    # Generate Model\n    model &#x3D; Model(inputs &#x3D; X, outputs &#x3D; Y)\n    \n    return model</code></pre>\n\n<ul>\n<li>pytorch</li>\n</ul>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"></code></pre>\n\n","feature":true,"text":" tensorflow ####################################################################################################################### # End AR...","link":"","photos":[],"count_time":{"symbolsCount":"4k","symbolsTime":"4 mins."},"categories":[],"tags":[],"toc":"","author":{"name":"LiuQuanZe","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"a good guy!","socials":{"github":"https://github.com/liuquanze","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/weixin_45895853","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"01背包理论基础02","uid":"a684fe7136f12073d2c44da23dc49f83","slug":"01背包理论基础02","date":"2023-01-31T06:31:17.000Z","updated":"2023-01-31T06:42:27.179Z","comments":true,"path":"api/articles/01背包理论基础02.json","keywords":null,"cover":null,"text":"01背包理论基础02题目描述：有n件物品和一个最多能背重量为w 的背包。第i件物品的重量是weight[i]，得到的价值是value[i] 。每件物品只能用一次，求解将哪些物品装入背包里物品价值总和最大。 背包问题（一维数组d实现，滚动数组）对于背包问题其实状态都是可以压缩的。 ...","link":"","photos":[],"count_time":{"symbolsCount":"2k","symbolsTime":"2 mins."},"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","count":114,"path":"api/categories/数据结构与算法.json"}],"tags":[{"name":"Java","slug":"Java","count":123,"path":"api/tags/Java.json"},{"name":"动态规划","slug":"动态规划","count":14,"path":"api/tags/动态规划.json"}],"author":{"name":"LiuQuanZe","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"a good guy!","socials":{"github":"https://github.com/liuquanze","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/weixin_45895853","juejin":"","customs":{}}},"feature":true}}